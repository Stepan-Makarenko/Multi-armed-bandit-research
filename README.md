# Multi-armed-bandit-research
The main purpose of this project is to try different multi-armed bandits - Epsilon-greedy, UCB, Thompson Sampling in different environments - Bernoulli, Gaussian
## Getting started
Run the following command:
```bash
git clone https://github.com/Stepan-Makarenko/Multi-armed-bandit-research.git
```
